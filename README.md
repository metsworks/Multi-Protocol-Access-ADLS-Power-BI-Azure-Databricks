# Multi-Protocol-Access-ADLS-Power-BI-Azure-Databricks

![Architecture du projet](docs/architecture.png)

Â« Pour des raisons de sÃ©curitÃ©, les captures d'Ã©cran et les notebooks qui contiennent les noms de ressources Azure internes ne sont disponibles que sur un repo privÃ©. Veuillez demamder l'accÃ¨s si besoin Â»
Â« For security reasons, the screenshots and notebooks containing internal Azure resource names are only available on a private repository. Please request access if needed.Â»

### ğŸ¯ Objectif

Cette implÃ©mentation prÃ©sente une architecture d'accÃ¨s aux donnÃ©es multiprotocole construite autour d'Azure Data Lake comme couche de stockage fondamentale et d'Azure Databricks comme environnement Data Lakehouse pour le traitement et le stockage des donnÃ©es.

Le workflow montre :

Comment les donnÃ©es stockÃ©es dans Azure Data Lake Storage Gen2 (ADLS) peuvent Ãªtre accessibles via plusieurs protocoles (par exemple, wasb://, abfss://) et intÃ©grÃ©es Ã  la fois Ã  Power BI et Azure Databricks.

Comment s'authentifier via une clÃ© de compte et un principal de service (Microsoft Entra ID) Ã  l'aide d'Azure Key Vault pour une gestion sÃ©curisÃ©e des secrets et RBAC / ACL pour les autorisations des utilisateurs et des services.

Comment ingÃ©rer l'ensemble de donnÃ©es du stockage Blob dans Databricks et l'enregistrer en tant que table Delta dans le catalogue Hive Metastore intÃ©grÃ©, fournissant des transactions ACID et des versions dans le cadre du framework Delta Lake.


### ğŸ”§ Services et technologies utilisÃ©s

Azure Data Lake Storage Gen2 (ADLS) â€“ Stockage hiÃ©rarchique

Azure Blob Storage â€“ Conteneur de fichiers CSV publics (ex : NYPD Arrests dataset)

Power BI Desktop â€“ Connexion via wasbs:// (Blob Storage REST endpoint)

Azure Databricks â€“ Connexion via abfss:// (Data Lake endpoint) avec :

Account Key Authentication

Service Principal Authentication (via Microsoft Entra ID â†’ App Registration)

Key Vault-backed Secret Scope

Azure Key Vault â€“ Gestion sÃ©curisÃ©e des secrets (client ID, client secret, account key)

Databricks Secret Scope â€“ Stockage des clÃ©s pour l'accÃ¨s aux ressources

Hive Metastore  â€“ Enregistrement automatique de la table au format Delta

### ğŸ”‘ MÃ©thodes dâ€™authentification dÃ©montrÃ©es
 1. Account Key Authentication (clÃ© dâ€™accÃ¨s directe du compte de stockage)

Utilisation de la propriÃ©tÃ© fs.azure.account.key.<STORAGE_ACCOUNT>.dfs.core.windows.net

AccÃ¨s configurÃ© depuis Databricks via spark.conf.set(...)

 2. Service Principal Authentication (recommandÃ© pour production)

CrÃ©ation dâ€™un App Registration dans Microsoft Entra ID

Attribution des rÃ´les (Storage Blob Data Contributor, Storage Blob Data Owner)

Gestion des permissions via ACL (Access Control Lists) sur les chemins ADLS

### âœ… RÃ©sultats obtenus

Fichier CSV chargÃ© depuis ADLS et injectÃ© :

dans Power BI via wasbs://

dans Azure Databricks via abfss://

Table Delta crÃ©Ã©e dans Databricks et enregistrÃ©e dans le Hive Metastore

AccÃ¨s sÃ©curisÃ© gÃ©rÃ© avec 2 mÃ©thodes dâ€™authentification

ClÃ©s et secrets protÃ©gÃ©s via Azure Key Vault et Databricks Secret Scope
